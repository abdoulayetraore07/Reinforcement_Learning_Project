# ğŸ¤– Reinforcement Learning Project: Maze & Morpion

## ğŸ“Œ Description
Ce dÃ©pÃ´t contient un projet d'apprentissage par renforcement rÃ©alisÃ© dans le cadre d'un cours Ã  l'ENSTA Paris. Nous avons implÃ©mentÃ© plusieurs algorithmes d'apprentissage par renforcement pour rÃ©soudre deux problÃ¨mes distincts :
1. Trouver la sortie d'un labyrinthe
2. CrÃ©er une IA capable de jouer au morpion (tic-tac-toe)

Ce projet dÃ©montre l'application de techniques d'apprentissage par renforcement comme Q-learning et SARSA Ã  des problÃ¨mes concrets, en utilisant diffÃ©rentes stratÃ©gies d'exploration.

---

## ğŸ› ï¸ FonctionnalitÃ©s
âœ… **Algorithmes d'apprentissage par renforcement** - Q-learning et SARSA  
âœ… **StratÃ©gies d'exploration** - Epsilon-greedy et Exploration de Boltzmann  
âœ… **RÃ©solution de labyrinthe** - Trouver le chemin optimal dans un environnement complexe  
âœ… **IA pour jeu de morpion** - Simple Q-learning et Double Q-learning  
âœ… **Chargement/Sauvegarde de modÃ¨les** - Persistance des tables Q pour rÃ©utilisation  

---

## ğŸ“‚ Structure du Projet

```
/Reinforcement_Learning_Project
â”‚â”€â”€ README.md                      # Ce fichier
â”‚â”€â”€ presentation.pptx              # PrÃ©sentation du projet
â”‚â”€â”€ Makefile                       # Fichier de compilation
â”‚
â”œâ”€â”€ Include/                       # Fichiers d'en-tÃªte
â”‚   â”‚â”€â”€ ...                        # Headers pour les algorithmes et environnements
â”‚
â”œâ”€â”€ src/                           # Code source
â”‚   â”‚â”€â”€ Q_learning.c               # ImplÃ©mentation de Q-learning
â”‚   â”‚â”€â”€ Sarsa.c                    # ImplÃ©mentation de SARSA
â”‚   â”‚â”€â”€ Morpion_Q.c                # Q-learning pour le jeu de morpion
â”‚   â”‚â”€â”€ Morpion_2Q.c               # Double Q-learning pour le jeu de morpion
â”‚   â”‚â”€â”€ ...                        # Autres fichiers source et environnements
â”‚
â””â”€â”€ Data/                          # DonnÃ©es pour les environnements
â”‚â”€â”€ maze.txt                   # Labyrinthe au format texte
â”‚â”€â”€ ...                        # Fichiers pour chargement/sauvegarde des tables Q
```

## ğŸ§  Algorithmes ImplÃ©mentÃ©s

### Q-learning
Q-learning est un algorithme d'apprentissage par renforcement qui apprend la valeur des actions dans des Ã©tats spÃ©cifiques en utilisant une table de valeurs Q, sans nÃ©cessiter un modÃ¨le de l'environnement. Il met Ã  jour les valeurs Q en maximisant les rÃ©compenses futures attendues.

### SARSA
SARSA (State-Action-Reward-State-Action) est un algorithme similaire qui met Ã  jour les valeurs Q en se basant sur la politique suivie. Contrairement au Q-learning qui utilise la meilleure action possible, SARSA utilise l'action effectivement choisie selon la politique actuelle.

### StratÃ©gies d'exploration
Deux fonctions sont disponibles pour la politique d'exploration :
- **Epsilon-greedy** : Rapide et efficace
- **Exploration de Boltzmann** : Plus sophistiquÃ©e mais plus lente en exÃ©cution

### Morpion (Tic-tac-toe)
Deux approches sont implÃ©mentÃ©es pour le jeu de morpion :
- **Q-learning** avec exploration epsilon-greedy
- **Double Q-learning** pour expÃ©rimentation

Nos tests ont montrÃ© que le Q-learning avec epsilon-greedy est plus efficace pour ce projet spÃ©cifique.

## ğŸš€ ExÃ©cution du Projet
Pour exÃ©cuter le projet, il suffit de taper `make` dans votre terminal. Vous obtiendrez les exÃ©cutables suivants :
- `Q_learning` : Q-learning pour le labyrinthe
- `Sarsa` : SARSA pour le labyrinthe
- `Morpion_Q` : Q-learning pour le morpion
- `Morpion_2Q` : Double Q-learning pour le morpion

Des descriptions dÃ©taillÃ©es peuvent Ãªtre trouvÃ©es dans les commentaires des algorithmes.

---

Merci pour votre lecture et bon apprentissage par renforcement !
